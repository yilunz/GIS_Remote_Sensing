{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw4_TinyImageNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yilunz/GIS_Remote_Sensing/blob/master/hw4_TinyImageNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnN9L844h8LF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from PIL import Image\n",
        "import torch.distributed as dist\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "from mpi4py import MPI\n",
        "import h5py\n",
        "import time\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVt61VbAawsU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_val_folder(val_dir):\n",
        "  path=os.path.join(val_dir,'images')\n",
        "  filename=os.path.join(val_dir,'val_annotations.txt')\n",
        "  fp=open(filename,\"r\")\n",
        "  data=fp.readlines()\n",
        "\n",
        "  val_img_dict={}\n",
        "  for line in data:\n",
        "    words=line.split(\"\\t\")\n",
        "    val_img_dict[words[0]]=words[1]\n",
        "  fp.close()\n",
        "  for img, folder in val_img_dict.items():\n",
        "    newpath=(os.path.join(path,folder))\n",
        "    if not os.path.exists(newpath):\n",
        "      os.makedirs(newpath)\n",
        "    if os.path.exists(os.path.join(path,img)):\n",
        "      os.rename(os.path.join(path,img),os.path.join(newpath,img))\n",
        "  return\n",
        "\n",
        "train_dir='/u/training/tra323/scratch/tiny-imagenet-200/train'\n",
        "train_dataset=datasets.ImageFolder(train_dir,transform=transform_train)\n",
        "print(train_dataset.class_to_idx)\n",
        "train_loader=torch.utils.data.DataLoader(train_dataset,batch_size=batch_size,shuffle=True, num_workers=8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_E7KmGCrgJn7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_dir='/u/training/tra323/scratch/tiny-imagenet-200/val/images'\n",
        "if 'val_' in os.listdir(val_dir)[0]:\n",
        "  create_val_folder(val_dir)\n",
        "else:\n",
        "  pass\n",
        "\n",
        "val_dataset=datasets.ImageFolder(val_dir,transform=transforms.ToTensor())\n",
        "print(val_dataset,class_to_idx)\n",
        "val_loader=torch.utils.data.DataLoader(val_dataset,batch_size=batch_size,shuffle=False,numworkers=8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0I24kB26Woi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size=128\n",
        "LR=0.001\n",
        "Num_Epochs=200\n",
        "num_output=100\n",
        "scheduler_step_size=50\n",
        "scheduler_gamma=0.5\n",
        "# c=3\n",
        "# Kernel_Size=3\n",
        "\n",
        "# transform_train=transforms.Compose([transforms.RandomHorizontalFlip(),transforms.RandomVerticalFlip(),transforms.ToTensor()])\n",
        "# transform_test=transforms.ToTensor()\n",
        "\n",
        "# #Load CIFAR 100 Dataset\n",
        "# trainset=torchvision.datasets.CIFAR100(root='~/scratch/',train=True, download=True,transform=transform_train)\n",
        "# trainloader = torch.utils.data.DataLoader(trainset,batch_size=batch_size,shuffle=True,num_workers=8)\n",
        "\n",
        "# testset=torchvision.datasets.CIFAR100(root='~/scratch/',train=False,download=True,transform=transform_test)\n",
        "# testloader=torch.utils.data.DataLoader(testset,batch_size=batch_size,shuffle=False,num_workers=8)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71oWXU3q3Nw9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BasicBlock(nn.Module):\n",
        "  def __init__(self,inplanes,planes,stride,padding,downsample=None):\n",
        "    super(BasicBlock,self).__init__()\n",
        "    self.conv1=nn.Conv2d(inplanes,planes,kernel_size=3,stride=stride,padding=padding)\n",
        "    #self.conv1=conv3x3(inplanes,planes,stride)\n",
        "    self.bn1=nn.BatchNorm2d(planes)\n",
        "    self.relu=nn.ReLU(inplace=True)\n",
        "    self.conv2=nn.Conv2d(planes,planes,kernel_size=3,stride=1,padding=padding) #stride should be 1 for the second conv\n",
        "    #self.conv2=conv3x3(planes,planes)\n",
        "    self.bn2=nn.BatchNorm2d(planes)\n",
        "    self.downsample=downsample\n",
        "    self.stride=stride\n",
        "  def forward(self,x):\n",
        "    residual=x\n",
        "    out=self.conv1(x)\n",
        "    out=self.bn1(out)\n",
        "    out=self.relu(out)\n",
        "    out=self.conv2(out)\n",
        "    out=self.bn2(out)\n",
        "    if self.downsample is not None:\n",
        "      residual = self.downsample(x)\n",
        "    #print(residual.shape)\n",
        "    #print(out.shape)\n",
        "    out+=residual\n",
        "    out=self.relu(out)\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsQNrs-aq7dE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ResNet,self).__init__()\n",
        "    self.conv3=nn.Conv2d(3,32,3,stride=1,padding=1)#32, kernel_size=3, stride=1, padding=1 [32,32,32]\n",
        "    self.bn3=nn.BatchNorm2d(32)\n",
        "    self.relu1=nn.ReLU()\n",
        "    self.dropout=nn.Dropout(p=0.5)\n",
        "\n",
        "    #self.downsample1=nn.Conv2d(3,32,kernel_size=1,stride=1)\n",
        "    self.bb1=BasicBlock(32,32,1,1,downsample=None) \n",
        "    self.bb2=BasicBlock(32,32,1,1,downsample=None)\n",
        "    self.dropout1=nn.Dropout(p=0.5)\n",
        "    \n",
        "    self.downsample1=nn.Conv2d(32,64,kernel_size=1,stride=2)\n",
        "    self.bb3=BasicBlock(32,64,2,1,downsample=self.downsample1)\n",
        "    self.bb4=BasicBlock(64,64,1,1,downsample=None)\n",
        "    self.bb5=BasicBlock(64,64,1,1,downsample=None)\n",
        "    self.bb6=BasicBlock(64,64,1,1,downsample=None)\n",
        "    self.dropout2=nn.Dropout(p=0.5)\n",
        "\n",
        "    self.downsample2=nn.Conv2d(64,128,kernel_size=1,stride=2)\n",
        "    self.bb7=BasicBlock(64,128,2,1,downsample=self.downsample2)\n",
        "    self.bb8=BasicBlock(128,128,1,1,downsample=None)\n",
        "    self.bb9=BasicBlock(128,128,1,1,downsample=None)\n",
        "    self.bb10=BasicBlock(128,128,1,1,downsample=None)\n",
        "    self.dropout3=nn.Dropout(p=0.5)\n",
        "\n",
        "    self.downsample3=nn.Conv2d(128,256,kernel_size=1,stride=2)\n",
        "    self.bb11=BasicBlock(128,256,2,1,downsample=self.downsample3)\n",
        "    self.bb12=BasicBlock(256,256,1,1,downsample=None)\n",
        "    self.dropout4=nn.Dropout(p=0.5)\n",
        "\n",
        "    self.maxpool=nn.MaxPool2d(kernel_size=3,stride=1)#2*2*256\n",
        "    self.fc1=nn.Linear(2*2*256,num_output)\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    out=self.conv3(x) #output size=32,32,32\n",
        "    out=self.bn3(out)\n",
        "    out=self.relu1(out)\n",
        "    out=self.dropout(out)\n",
        "    #print(out.size)\n",
        "\n",
        "    #stack1\n",
        "    out=self.bb1(out)#(in_channels,out_channels,stride)#[32,32,1]\n",
        "    out=self.bb2(out)\n",
        "    out=self.dropout1(out)\n",
        "\n",
        "    #stack2\n",
        "    out=self.bb3(out)\n",
        "    out=self.bb4(out)\n",
        "    out=self.bb5(out)\n",
        "    out=self.bb6(out)\n",
        "    out=self.dropout2(out)\n",
        "\n",
        "    #stack3\n",
        "    out=self.bb7(out)\n",
        "    out=self.bb8(out)\n",
        "    out=self.bb9(out)\n",
        "    out=self.bb10(out)\n",
        "    out=self.dropout3(out)\n",
        "\n",
        "    #stack4\n",
        "    out=self.bb11(out)\n",
        "    out=self.bb12(out)\n",
        "    out=self.dropout4(out)\n",
        "\n",
        "    #max pool\n",
        "    out=self.maxpool(out)\n",
        "    #print(out.shape)\n",
        "\n",
        "    #fully connected\n",
        "    out = out.view(-1,2*2*256) #flatten\n",
        "    out=self.fc1(out)\n",
        "    #print(out.shape)\n",
        "    return out\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chno7DgbNcQH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#basic_block=BasicBlock().to(device)\n",
        "resnet=ResNet().to(device)\n",
        "\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.RMSprop(resnet.parameters(),lr=LR,weight_decay=0.0005)\n",
        "scheduler=torch.optim.lr_scheduler.StepLR(optimizer,step_size=scheduler_step_size,gamma=scheduler_gamma)\n",
        "\n",
        "start_time=time.time()\n",
        "\n",
        "for epoch in range(Num_Epochs):\n",
        "  scheduler.step()\n",
        "  resnet.train()\n",
        "  total = 0\n",
        "  correct = 0\n",
        "  start_time = time.time()\n",
        "  for images,labels in train_loader:\n",
        "    images=images.to(device)\n",
        "    labels=labels.to(device)\n",
        "    outputs=resnet(images)\n",
        "    #print(outputs.shape)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss = criterion(outputs, labels)\n",
        "    _,predicted = torch.max(outputs,1)\n",
        "    total += labels.size(0)\n",
        "    \n",
        "    correct += (predicted == labels).sum().item()\n",
        "  \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  \n",
        "  train_accuracy = correct/total\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    resnet.eval()\n",
        "    correct=0\n",
        "    total=0\n",
        "    for images,labels in test_loader:\n",
        "      #images,labels = data\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "      outputs = resnet(images)\n",
        "\n",
        "      total += labels.size(0)\n",
        "      _,predicted = torch.max(outputs,1)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "    test_accuracy = correct/total\n",
        "  \n",
        "  print(\"Epoch {0}, Time {1:.4f}, Train Acc {2:.4f}, Test Acc {3:.4f}\".format(epoch, round(time.time()-start_time,4), round(train_accuracy,4), round(test_accuracy,4)))\n",
        "  torch.save(resnet.state_dict(),'epoch-{}.ckpt'.format(epoch))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}